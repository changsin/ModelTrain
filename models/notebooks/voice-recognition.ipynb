{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voice-recognition.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN6kNJ6DFS7zuisQst/y8sw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/ModelTrain/blob/main/models/notebooks/voice-recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3IR2E-4bPaO"
      },
      "source": [
        "# Voice recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/changsin/ModelTrain.git\n",
        "%cd ModelTrain/voice-recognition/\n",
        "\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "metadata": {
        "id": "TJ3ehFYkJ2VE",
        "outputId": "50470d5a-1c45-4b1c-e1c1-3f7bc9dfb3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.13.1+cu116 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "ZIKsa4GPvCI0",
        "outputId": "4ba73ecd-483c-4640-b5e1-a463fbf9e3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.28.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.1)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=cd43f15161365bbe5d1c1be778d1925d98ebe58e5d285fbb9f9344aa3ee67927\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, urllib3, smmap, setproctitle, docker-pycreds, sentry-sdk, gitdb, GitPython, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.15.0 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ModelTrain/models/voice-recognition\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from data import CustomTokenizer, CustomDataset\n",
        "from stt_model import Transformer\n",
        "\n",
        "max_length = 30\n",
        "batch_size = 32\n",
        "num_layers = 6\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "learning_rate = 5e-5\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "max_vocab_size = 5000\n",
        "\n",
        "def bind_model(model, parser):\n",
        "    # 학습한 모델을 저장하는 함수입니다.\n",
        "    def save(dir_name, *parser):\n",
        "        # directory\n",
        "        os.makedirs(dir_name, exist_ok=True)\n",
        "        save_dir = os.path.join(dir_name, 'checkpoint')\n",
        "        save_checkpoint(dict_for_infer, save_dir)\n",
        "\n",
        "        with open(os.path.join(dir_name, \"dict_for_infer\"), \"wb\") as f:\n",
        "            pickle.dump(dict_for_infer, f)\n",
        "\n",
        "        print(\"저장 완료!\")\n",
        "\n",
        "    # 저장한 모델을 불러올 수 있는 함수입니다.\n",
        "    def load(dir_name, *parser):\n",
        "        save_dir = os.path.join(dir_name, 'checkpoint')\n",
        "\n",
        "        global checkpoint\n",
        "        checkpoint = torch.load(save_dir)\n",
        "\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "        global dict_for_infer\n",
        "        with open(os.path.join(dir_name, \"dict_for_infer\"), 'rb') as f:\n",
        "            dict_for_infer = pickle.load(f)\n",
        "\n",
        "        print(\"로딩 완료!\")\n",
        "\n",
        "    # def infer(test_path, **kwparser):\n",
        "    #     device = checkpoint['device']\n",
        "    #     test_file_list = path_loader(test_path, is_test=True)\n",
        "    #     test_dataset = CustomDataset(test_file_list, None, 160000, 'test')\n",
        "    #     test_data_loader = DataLoader(test_dataset,\n",
        "    #                                   batch_size=10)\n",
        "    #     result_list = []\n",
        "\n",
        "    #     for step, batch in enumerate(test_data_loader):\n",
        "    #         inp = batch['magnitude'].to(device)\n",
        "    #         output, _ = evaluate(model, inp)\n",
        "    #         result_list.extend(output)\n",
        "\n",
        "    #     prob = [1] * len(result_list)\n",
        "\n",
        "    #     # DONOTCHANGE: They are reserved for nsml\n",
        "    #     # 리턴 결과는 [(확률, 0 or 1)] 의 형태로 보내야만 리더보드에 올릴 수 있습니다. 리더보드 결과에 확률의 값은 영향을 미치지 않습니다\n",
        "    #     # return list(zip(pred.flatten(), clipped.flatten()))\n",
        "    #     return list(zip(prob, result_list))\n",
        "\n",
        "    # # DONOTCHANGE: They are reserved for nsml\n",
        "    # # nsml에서 지정한 함수에 접근할 수 있도록 하는 함수입니다.\n",
        "    # nsml.bind(save=save, load=load, infer=infer)\n",
        "\n",
        "\n",
        "def evaluate(model, imgs):\n",
        "    model.to(device)\n",
        "    # as the target is english, the first word to the transformer should be the\n",
        "    # english start token.\n",
        "    tokenizer = dict_for_infer['tokenizer']\n",
        "    decoder_input = torch.tensor([tokenizer.txt2idx['<sos>']] * imgs.size(0), dtype=torch.long).to(device)\n",
        "    output = decoder_input.unsqueeze(1).to(device)\n",
        "    enc_output = None\n",
        "    for i in range(max_length + 1):\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        with torch.no_grad():\n",
        "            # predictions, attention_weights, enc_output = transformer([imgs, output, enc_output])\n",
        "            predictions, attention_weights, enc_output = model([imgs, output, enc_output])\n",
        "        # select the last token from the seq_len dimension\n",
        "        predictions_ = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = torch.tensor(torch.argmax(predictions_, axis=-1), dtype=torch.int32)\n",
        "\n",
        "        output = torch.cat([output, predicted_id], dim=-1)\n",
        "    output = output.cpu().numpy()\n",
        "\n",
        "    result_list = []\n",
        "    token_list = []\n",
        "    for token in output:\n",
        "        summary = tokenizer.convert(token)\n",
        "        result_list.append(summary)\n",
        "        token_list.append(token)\n",
        "\n",
        "    return result_list, token_list\n",
        "\n",
        "\n",
        "def train_step(batch_item, is_training):\n",
        "    src = batch_item['magnitude'].to(device)\n",
        "    tar = batch_item['target'].to(device)\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    print(\"batch_item: {}\".format(type(batch_item)))\n",
        "    print(\"src.shape: {} tar.shape: {}\".format(src.shape, tar.shape))\n",
        "    print(\"tar_inp.shape: {} tar_real.shape: {}\".format(tar_inp.shape,\n",
        "                                                        tar_real.shape))\n",
        "\n",
        "    if is_training:\n",
        "        # transformer.train()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output, _, _ = model([src, tar_inp, None])\n",
        "            # output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        return loss, acc, round(lr, 10)\n",
        "    else:\n",
        "        # transformer.eval()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output, _, _ = model([src, tar_inp, None])\n",
        "            # output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        return loss, acc\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    loss_ = criterion(pred.permute(0, 2, 1), real)\n",
        "    mask = torch.tensor(mask, dtype=loss_.dtype)\n",
        "    loss_ = mask * loss_\n",
        "\n",
        "    return torch.sum(loss_) / torch.sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    accuracies = torch.logical_and(mask, accuracies)\n",
        "    accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
        "    mask = torch.tensor(mask, dtype=torch.float32)\n",
        "\n",
        "    return torch.sum(accuracies) / torch.sum(mask)\n",
        "\n",
        "def glob_files(folder, file_type='*'):\n",
        "    search_string = os.path.join(folder, file_type)\n",
        "    files = glob(search_string)\n",
        "\n",
        "    print('Searching files ', search_string)\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        sub_paths = glob_files(f + '/')\n",
        "        paths += sub_paths\n",
        "      else:\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n",
        "\n",
        "\n",
        "def glob_folders(folder, file_type='*'):\n",
        "    search_string = os.path.join(folder, file_type)\n",
        "    files = glob(search_string)\n",
        "\n",
        "    print('Searching folders {} {}'.format(search_string, files))\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n",
        "\n",
        "\n",
        "def glob_files_all(folder, file_type='*'):\n",
        "    print(\"Searching in {} from {}\".format(folder, os.getcwd()))\n",
        "    sub_folders = glob_folders(folder)\n",
        "    print(\"Found {} sub folders\".format(len(sub_folders)))\n",
        "\n",
        "    files = []\n",
        "    for sub_folder in sub_folders:\n",
        "        tmp_files = glob_files(sub_folder, file_type)\n",
        "        if tmp_files:\n",
        "            files.extend(tmp_files)\n",
        "    print(\"Found {} files\".format(len(files)))\n",
        "    return files\n",
        "\n",
        "def path_loader(root_path, divide_id=8000, use_column=1, is_training=True):\n",
        "    print(\"root_path: {} divide_id: {} use_column: {} is_test: {}\".format(root_path, divide_id, use_column, is_training))\n",
        "\n",
        "    if is_training:\n",
        "        train_path = root_path\n",
        "        # os.path.join(root_path, 'train')\n",
        "        file_list = sorted(glob_files_all(os.path.join(train_path, 'train_data', '')))\n",
        "        # file_list = sorted(glob_files_all(os.path.join(train_path, 'train_lite', '')))\n",
        "        print(\"Data files loaded {}\".format(len(file_list)))\n",
        "        # file_list = sorted(glob(os.path.join(train_path, 'train_data', '*')))\n",
        "        # label = pd.read_csv(os.path.join(train_path, 'labels_tw_lite.txt'))\n",
        "        label = pd.read_csv(os.path.join(train_path, 'train_label.txt'))\n",
        "        # label = pd.read_csv(os.path.join(train_path, 'labels_ai-hub_tw_shuffle.txt'))\n",
        "        print(\"Loaded label {}\".format(len(label)))\n",
        "\n",
        "        file_dict = dict()\n",
        "        for full_file_path in file_list:\n",
        "            filename = Path(os.path.basename(full_file_path)).stem\n",
        "            if file_dict.get(filename.lower()):\n",
        "                print(\"ERROR: duplicate file name found {}\".format(filename))\n",
        "            else:\n",
        "                file_dict[filename.lower()] = full_file_path\n",
        "\n",
        "        print(\"file_dict {}\".format(len(file_dict)))\n",
        "        for id, (key, val) in enumerate(file_dict.items()):\n",
        "            print(\"{} {}\".format(key, val))\n",
        "            if id > 3:\n",
        "                break\n",
        "\n",
        "        file_list_selected = []\n",
        "        data_file_paths = label.iloc[:, 0]\n",
        "        for data_file_path in data_file_paths:\n",
        "            data_filename = Path(os.path.basename(data_file_path)).stem\n",
        "            data_filename = data_filename.replace(\"[\\\"\", \"\")\n",
        "            if file_dict.get(data_filename.lower()):\n",
        "                file_list_selected.append(file_dict[data_filename.lower()])\n",
        "            else:\n",
        "                print(\"ERROR: file not found {}\".format(data_filename))\n",
        "\n",
        "        return file_list_selected[:divide_id], label[:divide_id]\n",
        "\n",
        "    else:\n",
        "        return sorted(glob(os.path.join(root_path, 'test_data', '*')))\n",
        "\n",
        "def save_checkpoint(checkpoint, dir):\n",
        "    torch.save(checkpoint, os.path.join(dir))"
      ],
      "metadata": {
        "id": "mSYMeuf2r1o0",
        "outputId": "bc5ebc9e-db06-4b4c-ceb0-d39fba8d6df4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ModelTrain/models/voice-recognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "divide_id = 100\n",
        "use_column = 1\n",
        "\n",
        "DATASET_PATH = \"/content/ModelTrain/data/senior_voice_commands/train\"\n",
        "file_list, label = path_loader(DATASET_PATH, divide_id, use_column)\n",
        "\n",
        "print(\"Loaded files {} labels {}\".format(len(file_list), len(label)))\n",
        "\n",
        "split_num = int(len(label) * 0.9)\n",
        "train_file_list = file_list[:split_num]\n",
        "val_file_list = file_list[split_num:]\n",
        "\n",
        "train_label = label.iloc[:split_num]\n",
        "val_label = label.iloc[split_num:]\n",
        "\n",
        "tokenizer = CustomTokenizer(max_length=max_length, max_vocab_size=max_vocab_size)\n",
        "tokenizer.fit(train_label.iloc[:, 1])\n",
        "\n",
        "target_size = len(tokenizer.txt2idx)\n",
        "\n",
        "train_tokens = tokenizer.txt2token(train_label.iloc[:, 1])\n",
        "val_tokens = tokenizer.txt2token(val_label.iloc[:, 1])\n",
        "train_dataset = CustomDataset(train_file_list, train_tokens)\n",
        "valid_dataset = CustomDataset(val_file_list, val_tokens)\n",
        "\n",
        "print(\"train_tokens: {} train_file_list: {}\".format(len(train_tokens), len(train_file_list)))\n",
        "print(\"val_tokens: {} val_file_list: {}\".format(len(val_tokens), len(val_file_list)))\n",
        "\n",
        "print(\"train_token samples: {} train_file samples: {}\".format(train_label.iloc[:, 1][:3], train_file_list[:3]))\n",
        "print(\"val_token samples: {} val_file samples: {}\".format(val_label.iloc[:, 1][:3], val_file_list[:3]))\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "valid_dataloader = DataLoader(valid_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=False)\n"
      ],
      "metadata": {
        "id": "WHQFT3bJuPOF",
        "outputId": "5d30eb39-d5dc-4942-bd95-be646ad4b7e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root_path: /content/ModelTrain/data/senior_voice_commands/train divide_id: 100 use_column: 1 is_test: True\n",
            "Searching in /content/ModelTrain/data/senior_voice_commands/train/train_data/ from /content/ModelTrain/models/voice-recognition\n",
            "Searching folders /content/ModelTrain/data/senior_voice_commands/train/train_data/* ['/content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271']\n",
            "Found 1 sub folders\n",
            "Searching files  /content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/*\n",
            "Found 100 files\n",
            "Data files loaded 100\n",
            "Loaded label 100\n",
            "file_dict 100\n",
            "o_0271-13003-02-01-kes-f-08-a /content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13003-02-01-KES-F-08-A.wav\n",
            "o_0271-13004-02-01-kes-f-08-a /content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13004-02-01-KES-F-08-A.wav\n",
            "o_0271-13005-02-01-kes-f-08-a /content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13005-02-01-KES-F-08-A.wav\n",
            "o_0271-13006-02-01-kes-f-08-a /content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13006-02-01-KES-F-08-A.wav\n",
            "o_0271-13008-02-01-kes-f-08-a /content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13008-02-01-KES-F-08-A.wav\n",
            "Loaded files 100 labels 100\n",
            "train_tokens: 90 train_file_list: 90\n",
            "val_tokens: 10 val_file_list: 10\n",
            "train_token samples: 0     지금 사이트 즐겨 찾기에 넣어 줘.\n",
            "1      분위기 살려 주는 노래 알려 줘.\n",
            "2    나 혼자 있으니 아무 말이나 해 봐.\n",
            "Name: LabelText, dtype: object train_file samples: ['/content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13003-02-01-KES-F-08-A.wav', '/content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13004-02-01-KES-F-08-A.wav', '/content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13005-02-01-KES-F-08-A.wav']\n",
            "val_token samples: 90              문자 쓰는 것 좀 도와주겠니?\n",
            "91           오늘 비 올 확률이 얼마나 되는가?\n",
            "92    우리 다 나갑니다 보일러 외출 모드로 해 줘요.\n",
            "Name: LabelText, dtype: object val_file samples: ['/content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13137-02-01-KES-F-08-A.wav', '/content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13139-02-01-KES-F-08-A.wav', '/content/ModelTrain/data/senior_voice_commands/train/train_data/o_0271/o_0271-13140-02-01-KES-F-08-A.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    target_size=max_vocab_size + 4,\n",
        "    pe_target=max_length + 1,\n",
        "    device=device,\n",
        "    rate=dropout_rate\n",
        ")\n",
        "\n",
        "# bind_model(model=model, parser=args)\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "use_wandb = False\n",
        "if use_wandb:\n",
        "    wandb.init(\"voice-recognition\")\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gc.collect()\n",
        "    total_train_loss, total_valid_loss = 0, 0\n",
        "    total_train_acc, total_valid_acc = 0, 0\n",
        "\n",
        "    training = True\n",
        "    avg_batch_loss, avg_batch_acc = 0, 0\n",
        "    iterations = 0\n",
        "    for batch in train_dataloader:\n",
        "        batch = batch\n",
        "        batch_loss, batch_acc, lr = train_step(batch, training)\n",
        "        total_train_loss += batch_loss\n",
        "        total_train_acc += batch_acc\n",
        "        if use_wandb:\n",
        "            wandb.log({\"train_batch_acc\": batch_acc, \"train_batch_loss\":batch_loss})\n",
        "\n",
        "        avg_batch_loss += batch_loss\n",
        "        avg_batch_acc += batch_acc\n",
        "        iterations += 1\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log({\n",
        "            \"avg_train_batch_acc\": avg_batch_acc / float(iterations),\n",
        "            \"avg_train_batch_loss\": avg_batch_loss / float(iterations)})\n",
        "\n",
        "    print(f'avg_train_batch_acc: {avg_batch_acc / float(iterations)}')\n",
        "    print(f'avg_train_batch_loss: {avg_batch_acc / float(iterations)}')\n",
        "\n",
        "    training = False\n",
        "    iterations = 0\n",
        "    avg_batch_loss, avg_batch_acc = 0, 0\n",
        "    for batch in valid_dataloader:\n",
        "        batch = batch\n",
        "        batch_loss, batch_acc = train_step(batch, training)\n",
        "        total_valid_loss += batch_loss\n",
        "        total_valid_acc += batch_acc\n",
        "        if use_wandb:\n",
        "            wandb.log({\"valid_batch_acc\": batch_acc, \"valid_batch_loss\": batch_loss})\n",
        "\n",
        "        avg_batch_loss += batch_loss\n",
        "        avg_batch_acc += batch_acc\n",
        "        iterations += 1\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log({\"avg_valid_batch_acc\": avg_batch_acc/float(iterations),\n",
        "                    \"avg_valid_batch_loss\": avg_batch_loss/float(iterations)})\n",
        "\n",
        "    print('=================Epoch: {} Iterations: {}'.format(epoch, iterations))\n",
        "    print(f'avg_valid_batch_acc: {avg_batch_acc / float(iterations)}')\n",
        "    print(f'avg_valid_batch_loss: {avg_batch_acc / float(iterations)}')\n",
        "\n",
        "    print(f'total_train_loss: {total_train_loss}')\n",
        "    print(f'total_valid_loss: {total_valid_loss}')\n",
        "    print(f'total_train_acc : {total_train_acc}')\n",
        "    print(f'total_valid_acc : {total_valid_acc}')\n",
        "\n",
        "    dict_for_infer = {\n",
        "        'model': model.state_dict(),\n",
        "        'max_length': max_length,\n",
        "        'target_size': target_size,\n",
        "        'num_layers': num_layers,\n",
        "        'd_model': d_model,\n",
        "        'dff': dff,\n",
        "        'num_heads': num_heads,\n",
        "        'dropout_rate': dropout_rate,\n",
        "        'epochs': epochs,\n",
        "        'learning_rate': learning_rate,\n",
        "        'tokenizer': tokenizer,\n",
        "        'device': device\n",
        "    }\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log({\n",
        "            \"total_train_loss\": total_train_loss, \"total_valid_loss\": total_valid_loss,\n",
        "            \"total_train_acc\": total_train_acc,   \"total_valid_acc\": total_valid_acc\n",
        "                })\n",
        "    print(\"Writing to ./checkpoint_col{}_{}\".format(use_column, epoch))\n",
        "    save_checkpoint(checkpoint=dict_for_infer, dir='./checkpoint'.format(use_column))\n"
      ],
      "metadata": {
        "id": "-pt50XhbtDJM",
        "outputId": "355ca302-9c41-4281-ba42-237e6c8bc21e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ModelTrain/models/voice-recognition/stt_model.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
            "<ipython-input-73-5c2e079c9441>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  mask = torch.tensor(mask, dtype=loss_.dtype)\n",
            "<ipython-input-73-5c2e079c9441>:162: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
            "<ipython-input-73-5c2e079c9441>:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  mask = torch.tensor(mask, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([26, 3, 257, 313]) tar.shape: torch.Size([26, 32])\n",
            "tar_inp.shape: torch.Size([26, 31]) tar_real.shape: torch.Size([26, 31])\n",
            "avg_train_batch_acc: 0.0\n",
            "avg_train_batch_loss: 0.0\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([10, 3, 257, 313]) tar.shape: torch.Size([10, 32])\n",
            "tar_inp.shape: torch.Size([10, 31]) tar_real.shape: torch.Size([10, 31])\n",
            "=================Epoch: 0 Iterations: 1\n",
            "avg_valid_batch_acc: 0.0\n",
            "avg_valid_batch_loss: 0.0\n",
            "total_train_loss: 21.892440795898438\n",
            "total_valid_loss: 5.677505016326904\n",
            "total_train_acc : 0.0\n",
            "total_valid_acc : 0.0\n",
            "Writing to ./checkpoint_col1_0\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([26, 3, 257, 313]) tar.shape: torch.Size([26, 32])\n",
            "tar_inp.shape: torch.Size([26, 31]) tar_real.shape: torch.Size([26, 31])\n",
            "avg_train_batch_acc: 0.0\n",
            "avg_train_batch_loss: 0.0\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([10, 3, 257, 313]) tar.shape: torch.Size([10, 32])\n",
            "tar_inp.shape: torch.Size([10, 31]) tar_real.shape: torch.Size([10, 31])\n",
            "=================Epoch: 1 Iterations: 1\n",
            "avg_valid_batch_acc: 0.0\n",
            "avg_valid_batch_loss: 0.0\n",
            "total_train_loss: 15.256135940551758\n",
            "total_valid_loss: 4.865939140319824\n",
            "total_train_acc : 0.0\n",
            "total_valid_acc : 0.0\n",
            "Writing to ./checkpoint_col1_1\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([26, 3, 257, 313]) tar.shape: torch.Size([26, 32])\n",
            "tar_inp.shape: torch.Size([26, 31]) tar_real.shape: torch.Size([26, 31])\n",
            "avg_train_batch_acc: 0.0\n",
            "avg_train_batch_loss: 0.0\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([10, 3, 257, 313]) tar.shape: torch.Size([10, 32])\n",
            "tar_inp.shape: torch.Size([10, 31]) tar_real.shape: torch.Size([10, 31])\n",
            "=================Epoch: 2 Iterations: 1\n",
            "avg_valid_batch_acc: 0.0\n",
            "avg_valid_batch_loss: 0.0\n",
            "total_train_loss: 13.594927787780762\n",
            "total_valid_loss: 4.484981060028076\n",
            "total_train_acc : 0.0\n",
            "total_valid_acc : 0.0\n",
            "Writing to ./checkpoint_col1_2\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([26, 3, 257, 313]) tar.shape: torch.Size([26, 32])\n",
            "tar_inp.shape: torch.Size([26, 31]) tar_real.shape: torch.Size([26, 31])\n",
            "avg_train_batch_acc: 0.07489272207021713\n",
            "avg_train_batch_loss: 0.07489272207021713\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([10, 3, 257, 313]) tar.shape: torch.Size([10, 32])\n",
            "tar_inp.shape: torch.Size([10, 31]) tar_real.shape: torch.Size([10, 31])\n",
            "=================Epoch: 3 Iterations: 1\n",
            "avg_valid_batch_acc: 0.24867725372314453\n",
            "avg_valid_batch_loss: 0.24867725372314453\n",
            "total_train_loss: 12.589390754699707\n",
            "total_valid_loss: 4.2787065505981445\n",
            "total_train_acc : 0.2246781587600708\n",
            "total_valid_acc : 0.24867725372314453\n",
            "Writing to ./checkpoint_col1_3\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([32, 3, 257, 313]) tar.shape: torch.Size([32, 32])\n",
            "tar_inp.shape: torch.Size([32, 31]) tar_real.shape: torch.Size([32, 31])\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([26, 3, 257, 313]) tar.shape: torch.Size([26, 32])\n",
            "tar_inp.shape: torch.Size([26, 31]) tar_real.shape: torch.Size([26, 31])\n",
            "avg_train_batch_acc: 0.2385309636592865\n",
            "avg_train_batch_loss: 0.2385309636592865\n",
            "batch_item: <class 'dict'>\n",
            "src.shape: torch.Size([10, 3, 257, 313]) tar.shape: torch.Size([10, 32])\n",
            "tar_inp.shape: torch.Size([10, 31]) tar_real.shape: torch.Size([10, 31])\n",
            "=================Epoch: 4 Iterations: 1\n",
            "avg_valid_batch_acc: 0.24867725372314453\n",
            "avg_valid_batch_loss: 0.24867725372314453\n",
            "total_train_loss: 12.069853782653809\n",
            "total_valid_loss: 4.151733875274658\n",
            "total_train_acc : 0.7155928611755371\n",
            "total_valid_acc : 0.24867725372314453\n",
            "Writing to ./checkpoint_col1_4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "24sG2cJn1eGC",
        "outputId": "f567d492-fad0-4249-fdc2-a34cf0b9e463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchviz) (1.13.1+cu116)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4151 sha256=2aaad1051039da01a6e808076ee17a8b7ef4874e299470dd587c506135704897\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/7d/1b/8306781244e42ede119edbb053bdcda1c1f424ca226165a417\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchview\n",
        "\n",
        "from torchview import draw_graph\n",
        "from torchvision.models import resnet18, GoogLeNet, densenet, vit_b_16\n",
        "\n",
        "# model_graph = draw_graph(model, input_size=(1,3,224,224), expand_nested=True)\n",
        "model_graph = draw_graph(model, input_size=(3, 257, 313), expand_nested=True)\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "id": "Lx8NRzcOx0RM",
        "outputId": "0f1b46b4-8719-4572-9664-c6ffd0b76d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchview in /usr/local/lib/python3.8/dist-packages (0.2.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ModelTrain/models/voice-recognition/stt_model.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m_module_forward_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# this seems not to be necessary so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_orig_module_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ModelTrain/models/voice-recognition/stt_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         dec_output, attention_weights = self.decoder(\n\u001b[0m\u001b[1;32m    223\u001b[0m             tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m_module_forward_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# this seems not to be necessary so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_orig_module_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ModelTrain/models/voice-recognition/stt_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, enc_output, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m_module_forward_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# this seems not to be necessary so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_orig_module_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2179\u001b[0;31m         return handle_torch_function(\n\u001b[0m\u001b[1;32m   2180\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/overrides.py\u001b[0m in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;31m# implementations can do equality/identity comparisons.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_func_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             out = nn.parameter.Parameter.__torch_function__(\n\u001b[0m\u001b[1;32m    237\u001b[0m                 func, types, args, kwargs).as_subclass(RecorderTensor)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-fe5968ae83f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# model_graph = draw_graph(model, input_size=(1,3,224,224), expand_nested=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m257\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m313\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mdraw_graph\u001b[0;34m(model, input_data, input_size, graph_name, depth, device, dtypes, mode, strict, expand_nested, graph_dir, hide_module_functions, hide_inner_tensors, roll, show_shapes, save_graph, filename, directory, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     forward_prop(\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_recorder_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mmodel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_record_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown input type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;34m\"Failed to run torchgraph see error message\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         ) from e\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchgraph see error message"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "  print(batch['target'].shape)"
      ],
      "metadata": {
        "id": "2HG25If92OgE",
        "outputId": "8d96b6fa-6566-4eac-9021-bbbcabc797f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 32])\n",
            "torch.Size([32, 32])\n",
            "torch.Size([26, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataloader[0])"
      ],
      "metadata": {
        "id": "KlKMOmKy8dtX",
        "outputId": "53be9f35-b9d1-443f-fdd4-b0b567a93d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-f3a19466f118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "q9QG8YI32S_b",
        "outputId": "a7fbb414-7e57-4c88-d8c3-6a7e241a56ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (encoder): CNN_Encoder(\n",
            "    (feature_extract_model): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (embedding): Embedding(5004, 512)\n",
            "    (dec_layers): ModuleList(\n",
            "      (0): DecoderLayer(\n",
            "        (mha1): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (mha2): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (ffn): FFN(\n",
            "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (activation): ReLU()\n",
            "          (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        (layernorms1): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms2): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms3): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderLayer(\n",
            "        (mha1): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (mha2): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (ffn): FFN(\n",
            "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (activation): ReLU()\n",
            "          (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        (layernorms1): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms2): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms3): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (2): DecoderLayer(\n",
            "        (mha1): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (mha2): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (ffn): FFN(\n",
            "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (activation): ReLU()\n",
            "          (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        (layernorms1): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms2): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms3): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (3): DecoderLayer(\n",
            "        (mha1): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (mha2): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (ffn): FFN(\n",
            "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (activation): ReLU()\n",
            "          (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        (layernorms1): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms2): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms3): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (4): DecoderLayer(\n",
            "        (mha1): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (mha2): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (ffn): FFN(\n",
            "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (activation): ReLU()\n",
            "          (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        (layernorms1): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms2): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms3): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (5): DecoderLayer(\n",
            "        (mha1): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (mha2): MultiHeadAttention(\n",
            "          (wq): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wk): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wv): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (wo): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (ffn): FFN(\n",
            "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (activation): ReLU()\n",
            "          (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        (layernorms1): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms2): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (layernorms3): ModuleList(\n",
            "          (0): LayerNorm((1, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm((2, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (2): LayerNorm((3, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (3): LayerNorm((4, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (4): LayerNorm((5, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (5): LayerNorm((6, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (6): LayerNorm((7, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (7): LayerNorm((8, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (8): LayerNorm((9, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (9): LayerNorm((10, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (10): LayerNorm((11, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (11): LayerNorm((12, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (12): LayerNorm((13, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (13): LayerNorm((14, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (14): LayerNorm((15, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (15): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (16): LayerNorm((17, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (17): LayerNorm((18, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (18): LayerNorm((19, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (19): LayerNorm((20, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (20): LayerNorm((21, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (21): LayerNorm((22, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (22): LayerNorm((23, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (23): LayerNorm((24, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (24): LayerNorm((25, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (25): LayerNorm((26, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (26): LayerNorm((27, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (27): LayerNorm((28, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (28): LayerNorm((29, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (29): LayerNorm((30, 512), eps=1e-05, elementwise_affine=True)\n",
            "          (30): LayerNorm((31, 512), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (final_layer): Linear(in_features=512, out_features=5004, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader"
      ],
      "metadata": {
        "id": "I8gyO-hU3vyd",
        "outputId": "721bd2a6-5134-44e6-e326-abb165b29666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fdb55aaedc0>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_item = train_dataloader.dataset[0]\n",
        "type(batch_item)\n",
        "\n",
        "# src = batch_item['magnitude'].to(device)\n",
        "# tar = batch_item['target'].to(device)\n",
        "# tar_inp = tar[:, :-1]\n",
        "# tar_real = tar[:, 1:]\n",
        "\n",
        "# y = model([src, tar_inp, None])\n",
        "# make_dot(y.mean(), params=dict(model.named_parameters()))"
      ],
      "metadata": {
        "id": "_8HJciGo3e3z",
        "outputId": "b008249b-aaeb-444b-87e8-02f1d99fb34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar.shape"
      ],
      "metadata": {
        "id": "SRHKbW2U5D1A",
        "outputId": "d954d19f-e3ef-4448-e461-f5c16552c3f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colabcode\n",
        "from colabcode import ColabCode"
      ],
      "metadata": {
        "id": "mD_JvUTM42Kx",
        "outputId": "810e9c56-e43b-462a-b127-eb46ff2d7f19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colabcode\n",
            "  Downloading colabcode-0.3.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting pyngrok>=5.0.0\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 KB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jupyterlab==3.0.7\n",
            "  Downloading jupyterlab-3.0.7-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn==0.13.1\n",
            "  Downloading uvicorn-0.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio==1.4.3\n",
            "  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
            "Collecting jupyter-server~=1.2\n",
            "  Downloading jupyter_server-1.23.6-py3-none-any.whl (347 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.4/347.4 KB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (6.2)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (5.2.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (7.9.0)\n",
            "Collecting nbclassic~=0.2\n",
            "  Downloading nbclassic-0.5.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-server~=2.0\n",
            "  Downloading jupyterlab_server-2.19.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.0.7->colabcode) (23.0)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.8/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok>=5.0.0->colabcode) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.3.0)\n",
            "Collecting nbconvert>=6.4.4\n",
            "  Downloading nbconvert-7.2.9-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 KB\u001b[0m \u001b[31m590.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.1.12)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.7.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.8.0)\n",
            "Collecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.16.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.13.3)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.7.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (23.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->jupyterlab==3.0.7->colabcode) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (6.0.0)\n",
            "Collecting requests>=2.28\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2>=2.10\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.11.0)\n",
            "Collecting json5>=0.9.0\n",
            "  Downloading json5-0.9.11-py2.py3-none-any.whl (19 kB)\n",
            "Collecting jsonschema>=4.17.3\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbclassic~=0.2\n",
            "  Downloading nbclassic-0.5.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.8-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.7-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.6-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.5-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.4-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.2-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.4.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading nbclassic-0.3.7-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.8/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (6.3.0)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (57.4.0)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.8/dist-packages (from babel>=2.10->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.3->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.13.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->jupyterlab==3.0.7->colabcode) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (22.2.0)\n",
            "Collecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (5.10.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=6.1.12->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (4.6.3)\n",
            "Collecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.0.0)\n",
            "Collecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting tinycss2\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Collecting mistune<3,>=2.0.3\n",
            "  Downloading mistune-2.0.5-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.16.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyterlab==3.0.7->colabcode) (0.2.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2022.12.7)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.21)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19792 sha256=9e531bb3567cec40127202c1de99492c6fb083a6d383ebe599eb7ae633b0d606\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/f2/70/526da675d32f17577ec47ac4c663084efe39d47c826b6c3bb1\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: mistune, json5, websocket-client, tinycss2, sniffio, requests, pyngrok, pkgutil-resolve-name, nest-asyncio, jupyterlab-pygments, jinja2, jedi, h11, uvicorn, jsonschema, anyio, nbclient, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, nbclassic, jupyterlab, colabcode\n",
            "  Attempting uninstall: mistune\n",
            "    Found existing installation: mistune 0.8.4\n",
            "    Uninstalling mistune-0.8.4:\n",
            "      Successfully uninstalled mistune-0.8.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: nbconvert\n",
            "    Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyio-3.6.2 colabcode-0.3.0 h11-0.14.0 jedi-0.18.2 jinja2-3.1.2 json5-0.9.11 jsonschema-4.17.3 jupyter-server-1.23.6 jupyterlab-3.0.7 jupyterlab-pygments-0.2.2 jupyterlab-server-2.19.0 mistune-2.0.5 nbclassic-0.3.7 nbclient-0.7.2 nbconvert-7.2.9 nest-asyncio-1.4.3 notebook-shim-0.2.2 pkgutil-resolve-name-1.3.10 pyngrok-5.2.1 requests-2.28.2 sniffio-1.3.0 tinycss2-1.2.1 uvicorn-0.13.1 websocket-client-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ColabCode(port=10000, password=\"aiworks1!\")"
      ],
      "metadata": {
        "id": "L4H-zmvi5gS9",
        "outputId": "6894d63b-8be0-4abb-f2bf-9295bfc065ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Server can be accessed on: NgrokTunnel: \"https://d1b3-104-199-221-107.ngrok.io\" -> \"http://localhost:10000\"\n",
            "[2023-02-22T07:08:05.139Z] info  code-server 3.10.2 387b12ef4ca404ffd39d84834e1f0776e9e3c005\n",
            "[2023-02-22T07:08:05.140Z] info  Using user-data-dir ~/.local/share/code-server\n",
            "[2023-02-22T07:08:05.153Z] info  Using config file ~/.config/code-server/config.yaml\n",
            "[2023-02-22T07:08:05.153Z] info  HTTP server listening on http://127.0.0.1:10000 \n",
            "[2023-02-22T07:08:05.153Z] info    - Authentication is enabled\n",
            "[2023-02-22T07:08:05.153Z] info      - Using password from $PASSWORD\n",
            "[2023-02-22T07:08:05.153Z] info    - Not serving HTTPS \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.*"
      ],
      "metadata": {
        "id": "v69-2A9ua6ad",
        "outputId": "9b63bffc-be49-4367-c034-bdd4e9a478f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.*\n",
            "  Using cached protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.21.12\n",
            "    Uninstalling protobuf-4.21.12:\n",
            "      Successfully uninstalled protobuf-4.21.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull\n",
        "# %pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "!python main.py --epochs 10 --iteration 10"
      ],
      "metadata": {
        "id": "RDZC_r4GKE0V",
        "outputId": "8efa4f0e-5a7c-4435-c41e-e6ac5f9e8d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version:  1.13.1+cu116\n",
            "Searching in ../data/senior_voice_commands/train/train_data/ from /content/ModelTrain/voice-recognition\n",
            "Searching folders ../data/senior_voice_commands/train/train_data/* ['../data/senior_voice_commands/train/train_data/o_0271']\n",
            "Found 1 sub folders\n",
            "Searching files  ../data/senior_voice_commands/train/train_data/o_0271/*\n",
            "Found 450 files\n",
            "Data files loaded 450\n",
            "Loaded label 450\n",
            "train_tokens: 405 val_tokens: 45\n",
            "train_file_list: 405 val_file_list: 45\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ModelTrain/voice-recognition/wandb/run-20230210_232858-7jxzgryi\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mproud-bird-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/ModelTrain-voice-recognition\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/ModelTrain-voice-recognition/runs/7jxzgryi\u001b[0m\n",
            "/content/ModelTrain/voice-recognition/stt_model.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
            "main.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  mask = torch.tensor(mask, dtype=loss_.dtype)\n",
            "main.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
            "main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  mask = torch.tensor(mask, dtype=torch.float32)\n",
            "=================Epoch: 0\n",
            "total_train_loss: 75.65509796142578\n",
            "total_valid_loss: 8.865026473999023\n",
            "total_train_acc : 1.0900870561599731\n",
            "total_valid_acc : 0.4931968152523041\n",
            "=================Epoch: 1\n",
            "total_train_loss: 54.314971923828125\n",
            "total_valid_loss: 7.521265029907227\n",
            "total_train_acc : 3.5851738452911377\n",
            "total_valid_acc : 0.7122515439987183\n",
            "=================Epoch: 2\n",
            "total_train_loss: 46.348182678222656\n",
            "total_valid_loss: 6.6172261238098145\n",
            "total_train_acc : 5.169537544250488\n",
            "total_valid_acc : 0.8447725772857666\n",
            "=================Epoch: 3\n",
            "total_train_loss: 41.52682113647461\n",
            "total_valid_loss: 6.120863437652588\n",
            "total_train_acc : 5.6173481941223145\n",
            "total_valid_acc : 0.8998890519142151\n",
            "=================Epoch: 4\n",
            "total_train_loss: 38.310123443603516\n",
            "total_valid_loss: 5.761159420013428\n",
            "total_train_acc : 5.863459587097168\n",
            "total_valid_acc : 0.901285707950592\n",
            "=================Epoch: 5\n",
            "total_train_loss: 35.85946273803711\n",
            "total_valid_loss: 5.490602493286133\n",
            "total_train_acc : 5.884270191192627\n",
            "total_valid_acc : 0.9187219142913818\n",
            "=================Epoch: 6\n",
            "total_train_loss: 33.79389953613281\n",
            "total_valid_loss: 5.20768404006958\n",
            "total_train_acc : 5.91020393371582\n",
            "total_valid_acc : 0.9319827556610107\n",
            "=================Epoch: 7\n",
            "total_train_loss: 31.829748153686523\n",
            "total_valid_loss: 5.019711971282959\n",
            "total_train_acc : 6.032242774963379\n",
            "total_valid_acc : 0.9577842354774475\n",
            "=================Epoch: 8\n",
            "total_train_loss: 30.1312198638916\n",
            "total_valid_loss: 4.810881614685059\n",
            "total_train_acc : 6.1998491287231445\n",
            "total_valid_acc : 0.9668551683425903\n",
            "=================Epoch: 9\n",
            "total_train_loss: 28.909954071044922\n",
            "total_valid_loss: 4.71238374710083\n",
            "total_train_acc : 6.303613185882568\n",
            "total_valid_acc : 0.9717361330986023\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_train_acc ▁▄▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_train_loss █▅▄▃▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_valid_acc ▁▄▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_valid_loss █▆▄▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_train_acc 6.30361\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_train_loss 28.90995\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_valid_acc 0.97174\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_valid_loss 4.71238\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mproud-bird-12\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/changsin/ModelTrain-voice-recognition/runs/7jxzgryi\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230210_232858-7jxzgryi/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --epochs 10 --iteration 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2osqv-0xoTEq",
        "outputId": "8108000b-f3f4-4614-e190-0f8aa0214432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version:  1.13.1+cu116\n",
            "Searching in ../data/senior_voice_commands/train/train_data/ from /content/ModelTrain/voice-recognition\n",
            "Searching folders ../data/senior_voice_commands/train/train_data/* ['../data/senior_voice_commands/train/train_data/o_0271']\n",
            "Found 1 sub folders\n",
            "Searching files  ../data/senior_voice_commands/train/train_data/o_0271/*\n",
            "Found 450 files\n",
            "Data files loaded 450\n",
            "Loaded label 450\n",
            "train_tokens: 405 val_tokens: 45\n",
            "train_file_list: 405 val_file_list: 45\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangsin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ModelTrain/voice-recognition/wandb/run-20230210_235241-djikogau\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfresh-salad-13\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/ModelTrain-voice-recognition\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/changsin/ModelTrain-voice-recognition/runs/djikogau\u001b[0m\n",
            "/content/ModelTrain/voice-recognition/stt_model.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
            "main.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  mask = torch.tensor(mask, dtype=loss_.dtype)\n",
            "main.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
            "main.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  mask = torch.tensor(mask, dtype=torch.float32)\n",
            "=================Epoch: 0\n",
            "total_train_loss: 76.88773345947266\n",
            "total_valid_loss: 8.995746612548828\n",
            "total_train_acc : 1.2620514631271362\n",
            "total_valid_acc : 0.4918001592159271\n",
            "=================Epoch: 1\n",
            "total_train_loss: 54.65790939331055\n",
            "total_valid_loss: 7.573029518127441\n",
            "total_train_acc : 3.557147979736328\n",
            "total_valid_acc : 0.6585171222686768\n",
            "=================Epoch: 2\n",
            "total_train_loss: 46.28380584716797\n",
            "total_valid_loss: 6.64408016204834\n",
            "total_train_acc : 4.909660816192627\n",
            "total_valid_acc : 0.825248658657074\n",
            "=================Epoch: 3\n",
            "total_train_loss: 41.338966369628906\n",
            "total_valid_loss: 6.109131813049316\n",
            "total_train_acc : 5.67092227935791\n",
            "total_valid_acc : 0.901285707950592\n",
            "=================Epoch: 4\n",
            "total_train_loss: 38.02832794189453\n",
            "total_valid_loss: 5.818241596221924\n",
            "total_train_acc : 5.875349998474121\n",
            "total_valid_acc : 0.901285707950592\n",
            "=================Epoch: 5\n",
            "total_train_loss: 35.672752380371094\n",
            "total_valid_loss: 5.467609405517578\n",
            "total_train_acc : 5.890946865081787\n",
            "total_valid_acc : 0.9103566408157349\n",
            "=================Epoch: 6\n",
            "total_train_loss: 33.59981918334961\n",
            "total_valid_loss: 5.228265762329102\n",
            "total_train_acc : 5.948378562927246\n",
            "total_valid_acc : 0.9445233941078186\n",
            "=================Epoch: 7\n",
            "total_train_loss: 31.78477668762207\n",
            "total_valid_loss: 5.040624618530273\n",
            "total_train_acc : 6.049842357635498\n",
            "total_valid_acc : 0.9494189023971558\n",
            "=================Epoch: 8\n",
            "total_train_loss: 30.468441009521484\n",
            "total_valid_loss: 4.869378089904785\n",
            "total_train_acc : 6.181496620178223\n",
            "total_valid_acc : 0.9731327295303345\n",
            "=================Epoch: 9\n",
            "total_train_loss: 29.093568801879883\n",
            "total_valid_loss: 4.686411380767822\n",
            "total_train_acc : 6.289982318878174\n",
            "total_valid_acc : 0.9821891188621521\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_train_acc ▁▄▆▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_train_loss █▅▄▃▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_valid_acc ▁▃▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_valid_loss █▆▄▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_train_acc 6.28998\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_train_loss 29.09357\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  total_valid_acc 0.98219\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_valid_loss 4.68641\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfresh-salad-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/changsin/ModelTrain-voice-recognition/runs/djikogau\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230210_235241-djikogau/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IuSp3jnzvq0i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}